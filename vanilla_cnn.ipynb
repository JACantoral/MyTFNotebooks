{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with vanilla Convolutional Neural Network using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we built a simple 4-layer vanilla NN with MNIST. We saw, that this simple architecture achieved over 95% accuracy on the test dataset without much tunning (or any whatsoever). Thus, using Convolutional Neural Networks we should achive higher accuracy without much more effort. Then, we tried using CIFAR with basically the same simple architecture, achieving ~48% accuracy with 20 epochs, not so succesful.\n",
    "In this notebook, we will follow two different approaches to train a CNN with CIFAR10 data. First, it will be a simpler network with low level tensorflow using tf.gradients. Then, we will improve our model using tf.keras.conv2d layers, which will take care of updating parameters for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and preprocessing the data\n",
    "We will use the CIFAR10 dataset, which we will download from Alex Krizhevsky website at University of Toronto at https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "For more details of the CIFAR10, dataset please refer to https://www.cs.toronto.edu/~kriz/cifar.html or \n",
    "Krizhevsky, A., \"LearningMultipleLayersofFeaturesfromTinyImages\", 2009, https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\n",
    "Since, here we will only use CIFAR10 dataset, we don't need to load MNIST.\n",
    "Initially the notebook will follow a very similar style to that previously completed, likewise we will share some functions like the accuracy check and minibatch.\n",
    "\n",
    "Furthermore, to have a cleaner notebook, we will not include all the sanity checks we used in the previous notebooks, e.g. we will not check all the data types and shapes, since we already did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This functions load CIFAR 10 data (from binary files inside cifar-10-python.tar.gz). Notice that the files \n",
    "    have been 'untar-ed' manually into folder specified in path. This is convenient, since it is not ideal to \n",
    "    download the data everytime we run the notebook, particularly because CIFAR10 tar file is ~170MB.\n",
    "\n",
    "    These two functions are based on two function provided in data_utils.py in Stanford CNN for Visual \n",
    "    Recognition CS231n in (https://cs231n.github.io/assignments2019/assignment1/), and by Tensorflow cifar10.py as\n",
    "    in: https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/keras/_impl/keras/datasets/cifar10.py\n",
    "    and https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/keras/_impl/keras/datasets/cifar.py\n",
    "\n",
    "     Inputs:\n",
    "     - path: Path to CIFAR10 'untar-ed' files\n",
    "     \n",
    "     Outputs:\n",
    "     - (x_train, y_train), (x_test, y_test): Two tuples with numpy arrays containing the train and test data \n",
    "'''\n",
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "    \n",
    "def load_CIFAR10_data(path):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(path, 'data_batch_%d' % (b, ))\n",
    "        x, y = load_CIFAR_batch(f)\n",
    "        data.append(x)\n",
    "        labels.append(y)\n",
    "    x_train = np.concatenate(data)\n",
    "    y_train = np.concatenate(labels)\n",
    "    del x, y\n",
    "    x_test, y_test = load_CIFAR_batch(os.path.join(path, 'test_batch'))\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Using encoding 'latin1' prevents errors with objects that may have been pickled with Python2\n",
    "        d = pickle.load(f, encoding='latin1')    \n",
    "        data = d['data']\n",
    "        labels = d['labels']\n",
    "        data = data.reshape(10000, 3, 32, 32).transpose(0,2,3,1)\n",
    "        labels = np.array(labels)\n",
    "        return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command allows downloading the dataset directly\n",
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Otherwise, if the data have been downloaded before, it is possible to specify the path to the data files\n",
    "# and use the functions provided before\n",
    "# (x_train, y_train), (x_test, y_test)= load_CIFAR10_data('/home/josh/Documents/cs231n/cifar-10-batches')\n",
    "# (x_train, y_train), (x_test, y_test)= load_CIFAR10_data('/tf/mydata/s/Documents/cifar-10-batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
    "              'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (50000, 32, 32, 3)\n",
      "Train labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# It is a good idea to visualise the data we just loaded.\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image shape:  (32, 32, 3)\n",
      "The image is a:  Frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So, as expected we have 50,000 training images and 10,0000 for testing. What is\n",
    "# each image shape? Let's find out\n",
    "print('Train image shape: ', x_train[1].shape)\n",
    "\n",
    "# We can randomly show any of the numbers\n",
    "rnd_idx = np.random.randint(x_train.shape[0])\n",
    "plt.imshow(x_train[rnd_idx].astype(np.int32)) #Using astype guarantess imshow work\n",
    "print('The image is a: ', classes[y_train[rnd_idx, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity and to use default TF settings, we cast the data to int32 and float32\n",
    "# Since, the dataset is relatively small, in most cases, this is not a problem\n",
    "y_train = y_train.astype(np.int32).reshape(-1)\n",
    "y_test = y_test.astype(np.int32).reshape(-1)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we define a function to divide our data in N mini batches, this is an important step, to allow for mini batch \n",
    "# gradient descent\n",
    "\n",
    "def mini_batches(mini_batch_size, data_x, data_y = None):\n",
    "    # First we validate the data is of the expected type, and the number of labels meet the number of training samples\n",
    "    assert data_x.shape[0] == data_y.shape[0], 'X number of samples not equal to Y number of samples'\n",
    "    assert (isinstance(data_x, np.ndarray) and isinstance(data_y, np.ndarray)), 'Data not numpy array'\n",
    "    \n",
    "    N = data_x.shape[0] # Get the number of samples\n",
    "    idxs = np.arange(N) \n",
    "    # Shuffle data, this may not be so critical in this example, but it is important for most applications, to avoid\n",
    "    # strong correlations in mini batches\n",
    "    np.random.shuffle(idxs)\n",
    "    data_x = data_x[idxs] # Shuffle training samples\n",
    "    data_y = data_y[idxs] # Shuffle labels (don't forget)\n",
    "    \n",
    "    # Finally return the data in minibatches of the desired size\n",
    "    # List comprehension is so cool, technically this is returning a generator but the principle is the same\n",
    "    return ((data_x[i:i+mini_batch_size], data_y[i:i+mini_batch_size]) for i in range(0, N, mini_batch_size))\n",
    "\n",
    "type(mini_batches(64, x_test, y_test)) # Check type returned by function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Low Level CNN \n",
    "In this part of the notebook, we will implement a complete CNN using Low Level TF only. I.e., we will not use those nice Keras layers. We will use 2D convolutions, with defined weights, which will be updated with tf.gradients (I mean, not that low level after all). \n",
    "For this notebokk, we will follow a simple approach where all the filters are 3x3 in size.\n",
    "We will use 5-layer CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_five_layer_CNN(num_filters):\n",
    "    '''\n",
    "    This function will be used to initialise all the learnable parameters. For simplicity all the filters\n",
    "    are size 3x3.\n",
    "    \n",
    "    Inputs:\n",
    "    - num_filters: List containing the number of filters for each layer, including the input (e.g. 3 RGB channels)\n",
    "      This will have the shape [channels, k1, k2, k3, k4, classes]\n",
    "\n",
    "    Outputs:\n",
    "    - Parameters: Dictionary with network parameters, where element 'W1' and 'b1' represent weigth and bias\n",
    "      for layer one\n",
    "    '''\n",
    "    # Dictionary  to save  parameters\n",
    "    parameters = {}\n",
    "        \n",
    "    # Manually assing filter size \n",
    "    fsize = 3 \n",
    "    \n",
    "    # Number of filters\n",
    "    c, k1, k2, k3, k4, classes = num_filters\n",
    "\n",
    "    # For this architecture, we will use the more robust initialization described in:   \n",
    "    #     He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance \n",
    "    #     on ImageNet Classification, ICCV 2015, https://arxiv.org/abs/1502.01852\n",
    "    \n",
    "    parameters['W1'] = tf.Variable(tf.random_normal((fsize, fsize, c, k1), \n",
    "                          dtype=tf.float32) * np.sqrt(2.0 / ((32*32*c))),\n",
    "                          dtype=tf.float32, name='W1')\n",
    "    parameters['b1'] = tf.Variable(tf.zeros(k1, dtype=tf.float32), dtype=tf.float32, name='conv_b1')\n",
    "    \n",
    "    parameters['W2'] = tf.Variable(tf.random_normal((fsize, fsize, k1, k2),\n",
    "                          dtype=tf.float32) * np.sqrt(2.0 / (32*32*k1)),\n",
    "                          dtype=tf.float32, name='conv_w2')\n",
    "    parameters['b2'] = tf.Variable(tf.zeros(k2, dtype=tf.float32), dtype=tf.float32, name='conv_b2')\n",
    "    \n",
    "    parameters['W3'] = tf.Variable(tf.random_normal((fsize, fsize, k2, k3), \n",
    "                          dtype=tf.float32) * np.sqrt(2.0 / (16*16*k2)),\n",
    "                          dtype=tf.float32, name='conv_w3')\n",
    "    parameters['b3'] = tf.Variable(tf.zeros(k3, dtype=tf.float32), dtype=tf.float32, name='conv_b3')\n",
    "    \n",
    "    parameters['W4'] = tf.Variable(tf.random_normal((fsize, fsize, k3, k4), \n",
    "                          dtype=tf.float32) * np.sqrt(2.0 / (16*16*k3)),\n",
    "                          dtype=tf.float32, name='conv_w4')\n",
    "    parameters['b4'] = tf.Variable(tf.zeros(k4, dtype=tf.float32), dtype=tf.float32, name='conv_b4')\n",
    "    \n",
    "    \n",
    "    # If FC\n",
    "    parameters['W5'] = tf.Variable(tf.random_normal((8*8*k4, classes), \n",
    "                          dtype=tf.float32) * np.sqrt(2.0 / (8*8*k4)),\n",
    "                          dtype=tf.float32, name='W5')\n",
    "\n",
    "                                               \n",
    "    parameters['b5'] = tf.Variable(tf.zeros((classes), dtype=tf.float32), dtype=tf.float32, name='b5')\n",
    "\n",
    "    \n",
    "    return parameters, classes\n",
    "\n",
    "def five_layer_CNN(x, params, classes, training=True, dropout_p=0.5):\n",
    "    '''\n",
    "    Create the inference graph, define the network architecture.\n",
    "    Notice that Tensorflow data format is of the shape N x H x W x C\n",
    "    \n",
    "    Inputs:\n",
    "    - x: Tensor with training or test images of shape (N, 32, 32, 3) for CIFAR10\n",
    "    - params: Tuple with all the learnable weights and biases\n",
    "    - classes: number of classes, i.e. the neturons in the output layer\n",
    "    '''\n",
    "     \n",
    "    \n",
    "    # We use conv2d function to apply the filter, we will use 'SAME' convolutions so that the size is keep \n",
    "    # constant, depending on max pooling for downsampling. \n",
    "    \n",
    "    \n",
    "    # First layer\n",
    "    # The input shape is (N, H, W, C), filter shape is (fsize, fsize, C, K1)\n",
    "    # The output size after the convolution is then, (N, H, W, k1)\n",
    "    conv1_out = tf.nn.conv2d(input=x,\n",
    "                             filter=params['W1'], \n",
    "                             strides=[1,1,1,1],\n",
    "                             padding='SAME',\n",
    "                             name='conv1_out')\n",
    "    conv1_out += params['b1'][None, None, None, :] # Add bias, axes are added (reshape) to broadcast correctly\n",
    "    conv1_out_relu = tf.nn.relu(conv1_out, name='conv1_out_relu')\n",
    "    if training: conv1_out_relu = tf.nn.dropout(x=conv1_out_relu, keep_prob=dropout_p)\n",
    "    \n",
    "    # Second layer\n",
    "    # Input shape = (N, H, W, k1), filter shape = (fsize, fsize, k1, k2)\n",
    "    # Ouput shape = (N, H, W, k2)\n",
    "    conv2_out = tf.nn.conv2d(input=conv1_out_relu,\n",
    "                             filter=params['W2'],\n",
    "                             strides=[1,1,1,1],\n",
    "                             padding='SAME',\n",
    "                             name='conv2_out')\n",
    "    conv2_out += params['b2'][None, None, None, :] # Add bias, axes are added (reshape) to broadcast correctly\n",
    "    conv2_out_relu = tf.nn.relu(conv2_out, name='conv2_out_relu')\n",
    "    if training: conv2_out_relu = tf.nn.dropout(x=conv2_out_relu, keep_prob=dropout_p)\n",
    "    max_pooled_layer2 = tf.nn.max_pool(value=conv2_out_relu,\n",
    "                                       ksize=[1,2,2,1],\n",
    "                                       strides=[1,2,2,1],\n",
    "                                       padding='VALID',\n",
    "                                       data_format='NHWC',\n",
    "                                       name='max_pooled_layer2')\n",
    "   \n",
    "    # Third layer\n",
    "    # Input shape = (N, 16, 16, k2), filter shape = (fsize, fsize, k2, k3)\n",
    "    # Ouput shape = (N, 16, 16, k3)\n",
    "    conv3_out = tf.nn.conv2d(input=max_pooled_layer2,\n",
    "                             filter=params['W3'],\n",
    "                             strides=[1,1,1,1],\n",
    "                             padding='SAME',\n",
    "                             name='conv3_out')\n",
    "    conv3_out += params['b3'][None, None, None, :] # Add bias, axes are added (reshape) to broadcast correctly\n",
    "    conv3_out_relu = tf.nn.relu(conv3_out, name='conv3_out_relu')\n",
    "    if training: conv3_out_relu = tf.nn.dropout(x=conv3_out_relu, keep_prob=dropout_p)\n",
    "                          \n",
    "    # Fourth layer\n",
    "    # Input shape = (N, 16, 16, k3), filter shape = (fsize, fsize, k3, k4)\n",
    "    # Ouput shape = (N, 16, 16, k4)\n",
    "    conv4_out = tf.nn.conv2d(input=conv3_out_relu,\n",
    "                             filter=params['W4'],\n",
    "                             strides=[1,1,1,1],\n",
    "                             padding='SAME',\n",
    "                             name='conv4_out')\n",
    "    conv4_out += params['b4'][None, None, None, :] # Add bias, axes are added (reshape) to broadcast correctly\n",
    "    conv4_out_relu = tf.nn.relu(conv4_out, name='conv4_out_relu')\n",
    "    \n",
    "    if training: conv4_out_relu = tf.nn.dropout(x=conv4_out_relu, keep_prob=dropout_p)\n",
    "    \n",
    "    max_pooled_layer4 = tf.nn.max_pool(value=conv4_out_relu,\n",
    "                                       ksize=[1,2,2,1],\n",
    "                                       strides=[1,2,2,1],\n",
    "                                       padding='VALID',\n",
    "                                       data_format='NHWC',\n",
    "                                       name='max_pooled_layer4')\n",
    "                          \n",
    "    # Fifth layer\n",
    "    # Input shape = (N, 8, 8, k4), filter shape = (8 x 8 k4, classes)\n",
    "    # Ouput shape = (N, classes)\n",
    "    scores = tf.layers.flatten(max_pooled_layer4)\n",
    "    scores = tf.matmul(scores, params['W5']) + params['b5']\n",
    "        \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, training our model we will use a simple test function to check if the output shape tensor matches the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-9-5ae61772a1b2>:85: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-9-5ae61772a1b2>:140: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "(15, 10)\n"
     ]
    }
   ],
   "source": [
    "# Help function to test if the inference graph produces the expected output dimensions given an input\n",
    "# in this case the output should be of shape (N, 10)\n",
    "\n",
    "def test_vanilla_CNN(num_samples):\n",
    "    # Let us declare some useful constants\n",
    "    num_filters = [3, 16, 32, 32, 64, 10]\n",
    "    \n",
    "    # Reset the default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Define placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    \n",
    "    # Obtain parameters\n",
    "    parameters, classes = init_five_layer_CNN(num_filters)\n",
    "    \n",
    "    # Add scores to the graph\n",
    "    scores = five_layer_CNN(x, parameters, classes)\n",
    "    \n",
    "    # Create session and run it\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        test = sess.run(scores, feed_dict={x:x_train[:num_samples]})\n",
    "        print(test.shape)\n",
    "\n",
    "# Test our model output size\n",
    "test_vanilla_CNN(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the training model\n",
    "Let the fun begin! In this section we will build the trainin model.\n",
    "We will use a Tensorflow session to run the inference graph and the training operations. This will look similiar to test_vanilla_CNN(), plus the required components to define a loss function and carry out learning step operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define a function that will define the graph\n",
    "def train_CNN(num_filters,\n",
    "              num_epochs=10,\n",
    "              learning_rate=0.05,\n",
    "              reg=0.0,\n",
    "              print_every=100,\n",
    "              minibatch_size = 64,\n",
    "              dropout_p=0.5,\n",
    "              last_acc=0.0):\n",
    "    '''\n",
    "    This function will be used to run our training graph by creating a Tensorflow session.\n",
    "    \n",
    "    Inputs:\n",
    "    - num_filters: List containing the number of filters for each layer, including the input (e.g. 3 RGB channels)\n",
    "      This will usually have the shape [channels, k1, k2, k3, k4, classes]\n",
    "    - num_epochs: Integer with the number of epochs to run, an epoch is a complete pass in the whole training set\n",
    "    - learning_rate: Float with the learning rate to use for updates, i.e. the step size towards the minimum\n",
    "    - reg: L2 regularization strength, default is set to 0 for no regularization\n",
    "    - print_every: This is a helping variable to stop during training and evaluate loss functions and accuracy\n",
    "    - minibatch_size: Integer with the number of elements in minibatch\n",
    "    - best_acc: Best accuracy obtained this far of the training process\n",
    "    \n",
    "    Outputs:\n",
    "    - updated_parameters: List with update parameters\n",
    "    '''\n",
    "    \n",
    "    # Firstly, let's reset default graph.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Then, we will define placeholdersfor the training data, we need to be careful with the shape\n",
    "    x = tf.placeholder(tf.float32, [None, 32, 32, 3], name = 'x_train') # Training data\n",
    "    y = tf.placeholder(tf.int32, [None, ], name = 'y_train') # Training data\n",
    "    \n",
    "    # Let us add the nodes to the stored graphs, \n",
    "    tf.add_to_collection('images', x)\n",
    "    tf.add_to_collection('labels', y)\n",
    "    \n",
    "    # Let us obtain the parameters we will use to run the graph and compute the score\n",
    "    parameters_dict, classes = init_five_layer_CNN(num_filters)\n",
    "    \n",
    "    # Add the scores\n",
    "    scores = five_layer_CNN(x, parameters_dict, classes, dropout_p=dropout_p)\n",
    "    \n",
    "    # Add forward pass node\n",
    "    scores_test = five_layer_CNN(x, parameters_dict, classes,training=False)\n",
    "    \n",
    "    # Before moving on, save the scores so that we can run the graph from a restore\n",
    "    tf.add_to_collection('scores', scores)\n",
    "    \n",
    "    # Once the scores have been computed, we need to calculate our loss function (or error function)\n",
    "    # This will allow us to estimate how far we are from the true value\n",
    "#     losses = tf.contrib.kernel_methods.sparse_multiclass_hinge_loss(labels=y, logits=scores)\n",
    "    \n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = scores, labels=y)\n",
    "    data_loss = tf.reduce_mean(losses, name='data_loss') # In case we use regularisation on our weights\n",
    "    \n",
    "    # Add L2 regularisation, this will be a bit tedious\n",
    "    reg_loss = tf.reduce_mean(reg * (tf.nn.l2_loss(parameters_dict['W1']) #Check if reducing mean is needed\n",
    "               + tf.nn.l2_loss(parameters_dict['W2'])\n",
    "               + tf.nn.l2_loss(parameters_dict['W3'])\n",
    "               + tf.nn.l2_loss(parameters_dict['W4']) \n",
    "               + tf.nn.l2_loss(parameters_dict['W5'])))\n",
    "    \n",
    "    # Calculate total loss\n",
    "    loss = data_loss + reg_loss\n",
    "                 \n",
    "    # Now we need to use Tensorflow magic to calculate the gradients, remember that is still a bit of Low level\n",
    "    # tensorflow\n",
    "    # first, we need to convert the parameters dictionary to list\n",
    "#     **************************************************************************\n",
    "#     parameters = [(param) for (key, param) in parameters_dict.items()]\n",
    "    \n",
    "    parameters = [parameters_dict['W1'], \n",
    "                  parameters_dict['b1'], \n",
    "                  parameters_dict['W2'],\n",
    "                  parameters_dict['b2'],\n",
    "                  parameters_dict['W3'],\n",
    "                  parameters_dict['b3'],\n",
    "                  parameters_dict['W4'],\n",
    "                  parameters_dict['b4'],\n",
    "                  parameters_dict['W5'],\n",
    "                  parameters_dict['b5']]\n",
    "        \n",
    "    parameter_gradients = tf.gradients(loss, parameters)\n",
    "\n",
    "    # We need to update the weights manually, for this we can use tf.assign, or tf.assing_sub\n",
    "    # Using SGD, we need to update each parameter independently, so list comprehension works well\n",
    "    updated_parameters = [tf.assign_sub(w, learning_rate * grad) \n",
    "                          for w, grad in zip(parameters, parameter_gradients)]\n",
    "    \n",
    "   \n",
    "    # Save gradients\n",
    "    tf.add_to_collection('weights', updated_parameters)\n",
    "    \n",
    "    # Create saver to save the model\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Helping variables to save useful information\n",
    "    best_acc = 0.0\n",
    "    accuracies = np.zeros((int(x_train.shape[0]/minibatch_size/print_every)) + 1)\n",
    "    # Now, recall we have only created the graph, in order to run it and train, we need a Session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch: ', epoch)\n",
    "            for iteration, (x_mb, y_mb) in enumerate(mini_batches(minibatch_size, x_train, y_train)):\n",
    "                # The following line runs the loss for the minibatch.\n",
    "                # Recall TF knows what is needed to run a function and will run accordingy, e.g. scores before the\n",
    "                # loss. Also note that we only need to feed the data needed into a placeholder. In this case, we \n",
    "                # feed the minibatch training samples and labels\n",
    "                loss_mb, update_param = sess.run([loss, updated_parameters], feed_dict={x:x_mb, y:y_mb})\n",
    "                \n",
    "                if iteration % print_every == 0:\n",
    "                    # We define this function in the next cell\n",
    "                    accuracy = compute_accuracy(sess, minibatch_size, scores_test, x)\n",
    "                    accuracies[int(iteration/100)]=accuracy # save current accuracy\n",
    "#                     losses[int(iteration/print_every)] = loss_mb\n",
    "                    if accuracy > best_acc:\n",
    "                        best_acc = accuracy\n",
    "                        best_param = update_param\n",
    "                    print('Iteration: %d Loss: %f Accuracy: %f Learning rate: %f Regularization: %f'\n",
    "                          %(iteration, loss_mb, accuracy, learning_rate, reg))\n",
    "            \n",
    "            acc_range = np.max(accuracies) - np.min(accuracies)\n",
    "            print('Accuracies mean: %f Accuracies std: %f Range: %f' %(np.mean(accuracies), np.std(accuracies),\n",
    "                                                            acc_range))\n",
    "#             if (acc_range < 0.10):\n",
    "#                 learning_rate = 0.90 * learning_rate\n",
    "        if best_acc > last_acc:    \n",
    "            saver.save(sess, 'checkpoint_file')\n",
    "            \n",
    "        print('Best accuracy: %f', best_acc)\n",
    "\n",
    "        \n",
    "    return best_param, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(sess, minibatch_size, scores, x):\n",
    "    '''\n",
    "    This function computes the accuracy of the current model\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: it needs a current tf.Session to run the scores\n",
    "    - minibatch_size: The size of the mini batch to run the scores\n",
    "    - scores: TF operation to run\n",
    "    - x: test data\n",
    "    \n",
    "    Outputs:\n",
    "    - acc: Accuracy\n",
    "    \n",
    "    '''\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    for it, (xtest_mb, ytest_mb) in enumerate(mini_batches(minibatch_size, x_test, y_test)):\n",
    "        scores_test = sess.run(scores, feed_dict={x:xtest_mb})\n",
    "        y_pred = np.argmax(scores_test, axis=1)\n",
    "\n",
    "#         In case we would like to compare some elements of the predicted and ground truth arrays\n",
    "#         if it % 200 == 0:\n",
    "#             print('y_pred: ', y_pred[:10])\n",
    "#             print('y_test: ', ytest_mb[:10])\n",
    "\n",
    "        num_samples += xtest_mb.shape[0]\n",
    "        num_correct += np.sum(np.equal(y_pred, ytest_mb))\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.313336 Accuracy: 0.098400 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 100 Loss: 2.214496 Accuracy: 0.174400 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 200 Loss: 2.236074 Accuracy: 0.227000 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 300 Loss: 2.275856 Accuracy: 0.170900 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 400 Loss: 2.196395 Accuracy: 0.200400 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 500 Loss: 2.142207 Accuracy: 0.220100 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 600 Loss: 2.156872 Accuracy: 0.272200 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 700 Loss: 1.995912 Accuracy: 0.368800 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Accuracies mean: 0.216525 Accuracies std: 0.074565 Range: 0.270400\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.777213 Accuracy: 0.358700 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 100 Loss: 1.777369 Accuracy: 0.378500 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 200 Loss: 1.598953 Accuracy: 0.433600 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 300 Loss: 1.640850 Accuracy: 0.464100 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 400 Loss: 1.490343 Accuracy: 0.485200 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 500 Loss: 1.515072 Accuracy: 0.489700 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 600 Loss: 1.334801 Accuracy: 0.512800 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 700 Loss: 1.454241 Accuracy: 0.493800 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Accuracies mean: 0.452050 Accuracies std: 0.053103 Range: 0.154100\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.304224 Accuracy: 0.511900 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 100 Loss: 1.318139 Accuracy: 0.536600 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 200 Loss: 1.251917 Accuracy: 0.569300 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 300 Loss: 1.220747 Accuracy: 0.579900 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 400 Loss: 1.332962 Accuracy: 0.592100 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 500 Loss: 1.375816 Accuracy: 0.597600 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 600 Loss: 1.129750 Accuracy: 0.586400 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Iteration: 700 Loss: 1.118573 Accuracy: 0.599700 Learning rate: 0.011738 Regularization: 0.000096\n",
      "Accuracies mean: 0.571688 Accuracies std: 0.029513 Range: 0.087800\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.5997\n",
      "Accuracy with LR=0.011738 and Reg=0.000096 ---> 0.599700\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.350566 Accuracy: 0.097600 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 100 Loss: 2.340846 Accuracy: 0.129800 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 200 Loss: 2.333940 Accuracy: 0.156100 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 300 Loss: 2.286354 Accuracy: 0.175500 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 400 Loss: 2.159535 Accuracy: 0.218800 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 500 Loss: 1.991100 Accuracy: 0.258000 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 600 Loss: 2.110038 Accuracy: 0.380300 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 700 Loss: 1.952346 Accuracy: 0.434900 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Accuracies mean: 0.231375 Accuracies std: 0.112622 Range: 0.337300\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 2.023945 Accuracy: 0.374000 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 100 Loss: 1.686719 Accuracy: 0.431500 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 200 Loss: 1.652322 Accuracy: 0.487000 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 300 Loss: 1.968056 Accuracy: 0.403900 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 400 Loss: 1.363394 Accuracy: 0.522200 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 500 Loss: 1.226820 Accuracy: 0.510700 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 600 Loss: 1.447580 Accuracy: 0.526600 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 700 Loss: 1.406779 Accuracy: 0.564400 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Accuracies mean: 0.477538 Accuracies std: 0.062648 Range: 0.190400\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.893620 Accuracy: 0.443100 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 100 Loss: 1.228208 Accuracy: 0.554800 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 200 Loss: 1.427308 Accuracy: 0.566700 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 300 Loss: 1.187022 Accuracy: 0.593100 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 400 Loss: 1.156688 Accuracy: 0.600700 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 500 Loss: 1.129622 Accuracy: 0.613100 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 600 Loss: 1.177162 Accuracy: 0.521000 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Iteration: 700 Loss: 1.621410 Accuracy: 0.633500 Learning rate: 0.012249 Regularization: 0.002304\n",
      "Accuracies mean: 0.565750 Accuracies std: 0.056974 Range: 0.190400\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.6335\n",
      "Accuracy with LR=0.012249 and Reg=0.002304 ---> 0.633500\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.305203 Accuracy: 0.099000 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 100 Loss: 2.278283 Accuracy: 0.106500 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 200 Loss: 2.251815 Accuracy: 0.149600 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 300 Loss: 2.209003 Accuracy: 0.215200 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 400 Loss: 2.126684 Accuracy: 0.236000 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 500 Loss: 2.031752 Accuracy: 0.270600 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 600 Loss: 1.936947 Accuracy: 0.291800 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 700 Loss: 1.880509 Accuracy: 0.313900 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Accuracies mean: 0.210325 Accuracies std: 0.077896 Range: 0.214900\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.984788 Accuracy: 0.309600 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 100 Loss: 1.770354 Accuracy: 0.332500 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 200 Loss: 1.729133 Accuracy: 0.318700 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 300 Loss: 1.840610 Accuracy: 0.359200 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 400 Loss: 1.838725 Accuracy: 0.358800 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 500 Loss: 1.778497 Accuracy: 0.379400 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 600 Loss: 1.790696 Accuracy: 0.369300 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 700 Loss: 1.768209 Accuracy: 0.357500 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Accuracies mean: 0.348125 Accuracies std: 0.023305 Range: 0.069800\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.925876 Accuracy: 0.389200 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 100 Loss: 1.704915 Accuracy: 0.406400 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 200 Loss: 1.668713 Accuracy: 0.402000 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 300 Loss: 1.727274 Accuracy: 0.418500 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 400 Loss: 1.517244 Accuracy: 0.434900 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 500 Loss: 1.715675 Accuracy: 0.408400 Learning rate: 0.001014 Regularization: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 600 Loss: 1.690003 Accuracy: 0.437200 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Iteration: 700 Loss: 1.720581 Accuracy: 0.429500 Learning rate: 0.001014 Regularization: 0.000007\n",
      "Accuracies mean: 0.415762 Accuracies std: 0.016042 Range: 0.048000\n",
      "Best accuracy: %f 0.4372\n",
      "Accuracy with LR=0.001014 and Reg=0.000007 ---> 0.633500\n",
      "Best acc after 3 epochs: 0.633500 with lr: 1.224852e-02 and reg: 0.002304\n"
     ]
    }
   ],
   "source": [
    "# Let us train! We should expect achieving better perfomance than that we achieved with the fully connected\n",
    "# network in previous experiment. Here, we will experiment with hyperparameter selection\n",
    "num_filters = [3, 32, 64, 64, 128, 10]\n",
    "\n",
    "#10e-3 if random init with std = 0.01\n",
    "# Let us try for 10 combinations of regularization and learning rates\n",
    "total_tests = 3\n",
    "num_epochs = 3\n",
    "accuracies = {}\n",
    "best_acc = 0.0\n",
    "for test in range(total_tests):\n",
    "    learning_rate = 10**np.random.uniform(-4, -1)\n",
    "    reg = 10**np.random.uniform(-5.5, -2.5)\n",
    "    update_param, acc = train_CNN(\n",
    "                num_filters,\n",
    "                num_epochs=num_epochs,\n",
    "                learning_rate=learning_rate, \n",
    "                reg=reg,\n",
    "                print_every=100,\n",
    "                minibatch_size = 64, \n",
    "                dropout_p=1.0,\n",
    "                last_acc=best_acc)\n",
    "    accuracies[(learning_rate, reg)] = acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = update_param\n",
    "    print('Accuracy with LR=%f and Reg=%f ---> %f' %(learning_rate, reg, best_acc))\n",
    "    \n",
    "accs = sorted([(acc, lr_reg )for lr_reg, acc in accuracies.items()], reverse=1)\n",
    "print('Best acc after %d epochs: %f with lr: %e and reg: %f' \n",
    "      %(num_epochs, accs[0][0], accs[0][1][0], accs[0][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.388585 Accuracy: 0.118700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 2.282684 Accuracy: 0.190700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 2.233638 Accuracy: 0.237700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 1.975067 Accuracy: 0.322200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 2.253992 Accuracy: 0.343600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.962422 Accuracy: 0.315100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 1.854189 Accuracy: 0.380800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 1.716458 Accuracy: 0.405700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.289312 Accuracies std: 0.092268 Range: 0.287000\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.571440 Accuracy: 0.404000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 1.683835 Accuracy: 0.442400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 1.552814 Accuracy: 0.446800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 1.584646 Accuracy: 0.474700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 1.614527 Accuracy: 0.494900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.660610 Accuracy: 0.465000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 1.475443 Accuracy: 0.504400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 1.621600 Accuracy: 0.532600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.470600 Accuracies std: 0.037786 Range: 0.128600\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.661618 Accuracy: 0.497000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 1.394200 Accuracy: 0.535500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 1.097324 Accuracy: 0.559800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 1.346084 Accuracy: 0.558800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 1.709923 Accuracy: 0.559900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.496565 Accuracy: 0.576900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 1.229350 Accuracy: 0.578200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 1.201395 Accuracy: 0.539500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.550700 Accuracies std: 0.024789 Range: 0.081200\n",
      "Starting epoch:  3\n",
      "Iteration: 0 Loss: 1.242160 Accuracy: 0.508400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 1.134490 Accuracy: 0.590500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 1.005940 Accuracy: 0.594000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 1.244669 Accuracy: 0.614100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 0.922423 Accuracy: 0.616500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.456082 Accuracy: 0.614800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 1.070444 Accuracy: 0.616700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 1.246921 Accuracy: 0.628300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.597913 Accuracies std: 0.035798 Range: 0.119900\n",
      "Starting epoch:  4\n",
      "Iteration: 0 Loss: 1.309812 Accuracy: 0.611900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 1.107954 Accuracy: 0.640000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 0.970554 Accuracy: 0.638200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 1.004368 Accuracy: 0.652600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 0.952768 Accuracy: 0.662000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.169696 Accuracy: 0.644100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 0.917476 Accuracy: 0.649700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 1.123052 Accuracy: 0.666700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.645650 Accuracies std: 0.015827 Range: 0.054800\n",
      "Starting epoch:  5\n",
      "Iteration: 0 Loss: 0.984851 Accuracy: 0.663800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 0.876360 Accuracy: 0.669400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 1.047890 Accuracy: 0.660200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 0.922489 Accuracy: 0.666700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 1.124348 Accuracy: 0.642800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 1.030710 Accuracy: 0.683600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 1.105977 Accuracy: 0.673400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 0.997174 Accuracy: 0.690700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.668825 Accuracies std: 0.013691 Range: 0.047900\n",
      "Starting epoch:  6\n",
      "Iteration: 0 Loss: 1.259466 Accuracy: 0.667500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 0.846232 Accuracy: 0.680300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 0.710122 Accuracy: 0.693900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 0.870985 Accuracy: 0.691300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 0.719433 Accuracy: 0.688000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 0.947597 Accuracy: 0.693600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 0.773808 Accuracy: 0.673500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 0.798100 Accuracy: 0.699400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.685937 Accuracies std: 0.010385 Range: 0.031900\n",
      "Starting epoch:  7\n",
      "Iteration: 0 Loss: 0.935639 Accuracy: 0.691700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 1.078873 Accuracy: 0.661900 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 0.808085 Accuracy: 0.697000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 0.634317 Accuracy: 0.719400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 0.793812 Accuracy: 0.714100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 0.839390 Accuracy: 0.714200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 0.748642 Accuracy: 0.709500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 0.743701 Accuracy: 0.704000 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.701475 Accuracies std: 0.017303 Range: 0.057500\n",
      "Starting epoch:  8\n",
      "Iteration: 0 Loss: 0.840537 Accuracy: 0.711200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 0.840289 Accuracy: 0.698400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 0.622361 Accuracy: 0.718200 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 0.790151 Accuracy: 0.701300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 400 Loss: 0.788498 Accuracy: 0.706700 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 0.594235 Accuracy: 0.728500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 0.760509 Accuracy: 0.720300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 0.707932 Accuracy: 0.721400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.713250 Accuracies std: 0.009897 Range: 0.030100\n",
      "Starting epoch:  9\n",
      "Iteration: 0 Loss: 0.788336 Accuracy: 0.691300 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 100 Loss: 0.763158 Accuracy: 0.714100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 200 Loss: 0.991303 Accuracy: 0.710500 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 300 Loss: 0.680850 Accuracy: 0.718700 Learning rate: 0.005001 Regularization: 0.005310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400 Loss: 0.673483 Accuracy: 0.726600 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 500 Loss: 0.914727 Accuracy: 0.731800 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 600 Loss: 0.512291 Accuracy: 0.732100 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Iteration: 700 Loss: 0.975141 Accuracy: 0.692400 Learning rate: 0.005001 Regularization: 0.005310\n",
      "Accuracies mean: 0.714688 Accuracies std: 0.015065 Range: 0.040800\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.7321\n",
      "Accuracy with LR=0.005001 and Reg=0.005310 ---> 0.732100\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.324248 Accuracy: 0.111300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 2.276736 Accuracy: 0.138000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 2.165593 Accuracy: 0.225900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 2.125628 Accuracy: 0.324200 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 1.818237 Accuracy: 0.355000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 1.701903 Accuracy: 0.387100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 1.481294 Accuracy: 0.405900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 1.630293 Accuracy: 0.446100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.299188 Accuracies std: 0.117842 Range: 0.334800\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.688867 Accuracy: 0.447000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 1.687817 Accuracy: 0.413600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 1.643832 Accuracy: 0.488800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 1.307523 Accuracy: 0.511400 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 1.673274 Accuracy: 0.482100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 1.506534 Accuracy: 0.503900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 1.230659 Accuracy: 0.565900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 1.256813 Accuracy: 0.556600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.496163 Accuracies std: 0.047819 Range: 0.152300\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.749338 Accuracy: 0.554700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 1.189889 Accuracy: 0.570300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 1.454810 Accuracy: 0.569700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 1.088418 Accuracy: 0.634200 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 1.071971 Accuracy: 0.605100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 1.158317 Accuracy: 0.595500 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 1.017057 Accuracy: 0.597200 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 1.089365 Accuracy: 0.626700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.594175 Accuracies std: 0.026262 Range: 0.079500\n",
      "Starting epoch:  3\n",
      "Iteration: 0 Loss: 0.936944 Accuracy: 0.636700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.924805 Accuracy: 0.650500 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 1.098089 Accuracy: 0.653000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 1.057323 Accuracy: 0.663300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 1.004949 Accuracy: 0.674700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 1.087939 Accuracy: 0.668300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 1.168492 Accuracy: 0.681700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 1.150758 Accuracy: 0.655800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.660500 Accuracies std: 0.013530 Range: 0.045000\n",
      "Starting epoch:  4\n",
      "Iteration: 0 Loss: 0.968523 Accuracy: 0.639200 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.823790 Accuracy: 0.684400 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.787487 Accuracy: 0.686500 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.910469 Accuracy: 0.694600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.934326 Accuracy: 0.679400 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 0.796285 Accuracy: 0.701800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.741324 Accuracy: 0.693800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 0.896346 Accuracy: 0.706000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.685712 Accuracies std: 0.019431 Range: 0.066800\n",
      "Starting epoch:  5\n",
      "Iteration: 0 Loss: 0.698182 Accuracy: 0.676900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.559297 Accuracy: 0.710700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.743413 Accuracy: 0.692500 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.630256 Accuracy: 0.704300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.746291 Accuracy: 0.692900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 0.732008 Accuracy: 0.713800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.939730 Accuracy: 0.687900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 0.638146 Accuracy: 0.713600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.699075 Accuracies std: 0.012690 Range: 0.036900\n",
      "Starting epoch:  6\n",
      "Iteration: 0 Loss: 0.524141 Accuracy: 0.678600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.586930 Accuracy: 0.707100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.566590 Accuracy: 0.708300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.637709 Accuracy: 0.704000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.610074 Accuracy: 0.717700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 0.650132 Accuracy: 0.720700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.609039 Accuracy: 0.720900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 1.051034 Accuracy: 0.706400 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.707963 Accuracies std: 0.012775 Range: 0.042300\n",
      "Starting epoch:  7\n",
      "Iteration: 0 Loss: 0.569321 Accuracy: 0.709800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.676815 Accuracy: 0.715800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.554922 Accuracy: 0.725300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.471965 Accuracy: 0.709100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.422356 Accuracy: 0.727500 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 0.565131 Accuracy: 0.727000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.630814 Accuracy: 0.724100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 0.412885 Accuracy: 0.731600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.721275 Accuracies std: 0.008002 Range: 0.022500\n",
      "Starting epoch:  8\n",
      "Iteration: 0 Loss: 0.864330 Accuracy: 0.689900 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.580550 Accuracy: 0.705700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.536978 Accuracy: 0.719800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.523402 Accuracy: 0.699100 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.515329 Accuracy: 0.723000 Learning rate: 0.011381 Regularization: 0.001155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500 Loss: 0.432857 Accuracy: 0.715800 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.443064 Accuracy: 0.717400 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 0.615940 Accuracy: 0.735000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.713213 Accuracies std: 0.013403 Range: 0.045100\n",
      "Starting epoch:  9\n",
      "Iteration: 0 Loss: 0.500949 Accuracy: 0.714000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 100 Loss: 0.459154 Accuracy: 0.726300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 200 Loss: 0.202881 Accuracy: 0.730000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 300 Loss: 0.436598 Accuracy: 0.719000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 400 Loss: 0.474207 Accuracy: 0.710000 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 500 Loss: 0.360677 Accuracy: 0.722600 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 600 Loss: 0.368005 Accuracy: 0.725700 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Iteration: 700 Loss: 0.340004 Accuracy: 0.735300 Learning rate: 0.011381 Regularization: 0.001155\n",
      "Accuracies mean: 0.722862 Accuracies std: 0.007782 Range: 0.025300\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.7353\n",
      "Accuracy with LR=0.011381 and Reg=0.001155 ---> 0.735300\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.311070 Accuracy: 0.109600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 2.376114 Accuracy: 0.136900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 2.091712 Accuracy: 0.194100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 2.167772 Accuracy: 0.275600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 1.818285 Accuracy: 0.233400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 1.966162 Accuracy: 0.367400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 1.891199 Accuracy: 0.396300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 1.643410 Accuracy: 0.433500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.268350 Accuracies std: 0.113316 Range: 0.323900\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.467223 Accuracy: 0.415100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 1.729946 Accuracy: 0.472300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 1.395465 Accuracy: 0.488900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 1.410297 Accuracy: 0.463100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 1.335883 Accuracy: 0.510600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 1.391499 Accuracy: 0.531200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 1.363438 Accuracy: 0.541200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 1.435673 Accuracy: 0.532900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.494412 Accuracies std: 0.040429 Range: 0.126100\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.375880 Accuracy: 0.566400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 1.026959 Accuracy: 0.570900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.814084 Accuracy: 0.568300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 1.134297 Accuracy: 0.583900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.885172 Accuracy: 0.587000 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 1.179036 Accuracy: 0.605700 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 1.097162 Accuracy: 0.571400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.948511 Accuracy: 0.614800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.583550 Accuracies std: 0.017006 Range: 0.048400\n",
      "Starting epoch:  3\n",
      "Iteration: 0 Loss: 0.980297 Accuracy: 0.576600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 1.299830 Accuracy: 0.601200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.757959 Accuracy: 0.643100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 1.005960 Accuracy: 0.639400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.850897 Accuracy: 0.645500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.978004 Accuracy: 0.640100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 1.181244 Accuracy: 0.615800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 1.173269 Accuracy: 0.630200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.623988 Accuracies std: 0.022901 Range: 0.068900\n",
      "Starting epoch:  4\n",
      "Iteration: 0 Loss: 0.998012 Accuracy: 0.655100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 1.098341 Accuracy: 0.649000 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.898258 Accuracy: 0.669100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.987910 Accuracy: 0.628600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.831241 Accuracy: 0.660800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.737152 Accuracy: 0.666900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 0.614031 Accuracy: 0.668900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.447394 Accuracy: 0.686300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.660587 Accuracies std: 0.015930 Range: 0.057700\n",
      "Starting epoch:  5\n",
      "Iteration: 0 Loss: 1.109619 Accuracy: 0.645500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 0.622248 Accuracy: 0.677100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.822246 Accuracy: 0.685200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.660751 Accuracy: 0.683800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.843567 Accuracy: 0.678700 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.811002 Accuracy: 0.698500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 0.624988 Accuracy: 0.699000 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.654992 Accuracy: 0.703400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.683900 Accuracies std: 0.017215 Range: 0.057900\n",
      "Starting epoch:  6\n",
      "Iteration: 0 Loss: 0.684886 Accuracy: 0.697700 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 0.795628 Accuracy: 0.675500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.489795 Accuracy: 0.705200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.681936 Accuracy: 0.716000 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.747836 Accuracy: 0.703400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.573035 Accuracy: 0.697700 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 0.614295 Accuracy: 0.709100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.713787 Accuracy: 0.708900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.701688 Accuracies std: 0.011427 Range: 0.040500\n",
      "Starting epoch:  7\n",
      "Iteration: 0 Loss: 0.642457 Accuracy: 0.704400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 0.633566 Accuracy: 0.700200 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.582490 Accuracy: 0.711900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.573520 Accuracy: 0.701800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.662165 Accuracy: 0.714600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.645098 Accuracy: 0.701400 Learning rate: 0.009053 Regularization: 0.000414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 600 Loss: 0.690028 Accuracy: 0.712300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.551452 Accuracy: 0.710900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.707187 Accuracies std: 0.005434 Range: 0.014400\n",
      "Starting epoch:  8\n",
      "Iteration: 0 Loss: 0.871712 Accuracy: 0.665500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 0.428335 Accuracy: 0.693400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.312995 Accuracy: 0.721100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.394369 Accuracy: 0.710500 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.600250 Accuracy: 0.707800 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.835671 Accuracy: 0.708900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 0.670497 Accuracy: 0.696100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.497467 Accuracy: 0.716300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.702450 Accuracies std: 0.016440 Range: 0.055600\n",
      "Starting epoch:  9\n",
      "Iteration: 0 Loss: 0.630336 Accuracy: 0.696600 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 100 Loss: 0.341946 Accuracy: 0.721700 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 200 Loss: 0.589828 Accuracy: 0.704400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 300 Loss: 0.408796 Accuracy: 0.721300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 400 Loss: 0.542366 Accuracy: 0.714900 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 500 Loss: 0.493344 Accuracy: 0.712400 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 600 Loss: 0.572857 Accuracy: 0.713100 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Iteration: 700 Loss: 0.648843 Accuracy: 0.713300 Learning rate: 0.009053 Regularization: 0.000414\n",
      "Accuracies mean: 0.712212 Accuracies std: 0.007799 Range: 0.025100\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.7217\n",
      "Accuracy with LR=0.009053 and Reg=0.000414 ---> 0.735300\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.421113 Accuracy: 0.100100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 2.419143 Accuracy: 0.132300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 2.618978 Accuracy: 0.106100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 2.177220 Accuracy: 0.244300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 2.128539 Accuracy: 0.272300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 2.198841 Accuracy: 0.350700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 2.049220 Accuracy: 0.355500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 1.867248 Accuracy: 0.340700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.237750 Accuracies std: 0.103596 Range: 0.255400\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 1.743670 Accuracy: 0.372300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 1.818910 Accuracy: 0.399600 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 1.790865 Accuracy: 0.429700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 1.487257 Accuracy: 0.486400 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.487430 Accuracy: 0.512200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 1.438797 Accuracy: 0.453900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 1.436071 Accuracy: 0.558200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 1.447936 Accuracy: 0.521000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.466663 Accuracies std: 0.059923 Range: 0.185900\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.741674 Accuracy: 0.447100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 1.476211 Accuracy: 0.584600 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 1.250324 Accuracy: 0.581700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 1.318431 Accuracy: 0.600200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.072523 Accuracy: 0.623800 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 1.241581 Accuracy: 0.599600 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 1.044608 Accuracy: 0.617700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 1.093642 Accuracy: 0.610000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.583087 Accuracies std: 0.053200 Range: 0.176700\n",
      "Starting epoch:  3\n",
      "Iteration: 0 Loss: 1.126904 Accuracy: 0.644000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 1.068486 Accuracy: 0.651900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.991178 Accuracy: 0.634000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 1.042237 Accuracy: 0.667800 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.192418 Accuracy: 0.675300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 1.203546 Accuracy: 0.665700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 1.074717 Accuracy: 0.674400 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 0.942156 Accuracy: 0.679200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.661538 Accuracies std: 0.015338 Range: 0.045200\n",
      "Starting epoch:  4\n",
      "Iteration: 0 Loss: 0.967142 Accuracy: 0.616200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 1.152300 Accuracy: 0.692100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 1.152216 Accuracy: 0.669700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 0.964126 Accuracy: 0.663200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.113166 Accuracy: 0.639100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 0.893751 Accuracy: 0.652900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 0.782652 Accuracy: 0.695800 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 1.159484 Accuracy: 0.710100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.667388 Accuracies std: 0.029359 Range: 0.093900\n",
      "Starting epoch:  5\n",
      "Iteration: 0 Loss: 0.899820 Accuracy: 0.669700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 0.779468 Accuracy: 0.709500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.970126 Accuracy: 0.698500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 1.068332 Accuracy: 0.691500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.046925 Accuracy: 0.710300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 0.899538 Accuracy: 0.704500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 0.781580 Accuracy: 0.690100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 1.379414 Accuracy: 0.697000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.696387 Accuracies std: 0.012307 Range: 0.040600\n",
      "Starting epoch:  6\n",
      "Iteration: 0 Loss: 1.860452 Accuracy: 0.593900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 0.863899 Accuracy: 0.684800 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.872848 Accuracy: 0.703300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 0.815401 Accuracy: 0.728000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 0.785357 Accuracy: 0.714700 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 1.018938 Accuracy: 0.689500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 0.828235 Accuracy: 0.703100 Learning rate: 0.023700 Regularization: 0.006558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 700 Loss: 0.860916 Accuracy: 0.702900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.690025 Accuracies std: 0.038457 Range: 0.134100\n",
      "Starting epoch:  7\n",
      "Iteration: 0 Loss: 1.023264 Accuracy: 0.656100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 0.666627 Accuracy: 0.728900 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.844265 Accuracy: 0.699100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 0.685179 Accuracy: 0.725300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 0.625254 Accuracy: 0.719400 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 0.913281 Accuracy: 0.708500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 1.031570 Accuracy: 0.694200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 0.688392 Accuracy: 0.723800 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.706913 Accuracies std: 0.022555 Range: 0.072800\n",
      "Starting epoch:  8\n",
      "Iteration: 0 Loss: 1.359265 Accuracy: 0.657000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 0.885639 Accuracy: 0.690000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.971452 Accuracy: 0.706100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 0.844726 Accuracy: 0.709200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 0.816715 Accuracy: 0.705300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 0.782372 Accuracy: 0.707400 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 0.759316 Accuracy: 0.727100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 0.705911 Accuracy: 0.723000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.703137 Accuracies std: 0.020428 Range: 0.070100\n",
      "Starting epoch:  9\n",
      "Iteration: 0 Loss: 1.567966 Accuracy: 0.575000 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 100 Loss: 0.612734 Accuracy: 0.726500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 200 Loss: 0.790813 Accuracy: 0.685200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 300 Loss: 0.745356 Accuracy: 0.702300 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 400 Loss: 1.132159 Accuracy: 0.703100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 500 Loss: 0.794163 Accuracy: 0.719200 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 600 Loss: 0.813170 Accuracy: 0.731500 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Iteration: 700 Loss: 0.610629 Accuracy: 0.712100 Learning rate: 0.023700 Regularization: 0.006558\n",
      "Accuracies mean: 0.694362 Accuracies std: 0.047189 Range: 0.156500\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.7315\n",
      "Accuracy with LR=0.023700 and Reg=0.006558 ---> 0.735300\n",
      "Starting epoch:  0\n",
      "Iteration: 0 Loss: 2.310759 Accuracy: 0.101900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 2.369915 Accuracy: 0.202600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 2.275224 Accuracy: 0.236300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 2.219120 Accuracy: 0.250900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 2.005392 Accuracy: 0.295800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 1.851546 Accuracy: 0.384100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 1.979692 Accuracy: 0.366500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 1.632475 Accuracy: 0.409700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.280975 Accuracies std: 0.097372 Range: 0.307800\n",
      "Starting epoch:  1\n",
      "Iteration: 0 Loss: 2.099884 Accuracy: 0.420500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 1.712371 Accuracy: 0.428800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 1.494274 Accuracy: 0.458800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 1.507001 Accuracy: 0.382600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 1.438882 Accuracy: 0.505300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 1.408559 Accuracy: 0.510700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 1.429591 Accuracy: 0.536200 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 1.423171 Accuracy: 0.506700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.468700 Accuracies std: 0.050659 Range: 0.153600\n",
      "Starting epoch:  2\n",
      "Iteration: 0 Loss: 1.387058 Accuracy: 0.532500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 1.421361 Accuracy: 0.533900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 1.358806 Accuracy: 0.569000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 1.442549 Accuracy: 0.563000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 1.353461 Accuracy: 0.559000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 1.286342 Accuracy: 0.583400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 1.092133 Accuracy: 0.593600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 1.172700 Accuracy: 0.600700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.566887 Accuracies std: 0.023670 Range: 0.068200\n",
      "Starting epoch:  3\n",
      "Iteration: 0 Loss: 1.062042 Accuracy: 0.580500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.991569 Accuracy: 0.614800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 1.079284 Accuracy: 0.625400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 1.106844 Accuracy: 0.633000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 1.152613 Accuracy: 0.590600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.832088 Accuracy: 0.627200 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.866178 Accuracy: 0.638100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.935690 Accuracy: 0.639300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.618613 Accuracies std: 0.020574 Range: 0.058800\n",
      "Starting epoch:  4\n",
      "Iteration: 0 Loss: 1.187721 Accuracy: 0.553200 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.942793 Accuracy: 0.646500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 0.930002 Accuracy: 0.642100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.900274 Accuracy: 0.670500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.832963 Accuracy: 0.639500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 1.260548 Accuracy: 0.613400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 1.067184 Accuracy: 0.669100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.964945 Accuracy: 0.678500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.639100 Accuracies std: 0.037983 Range: 0.125300\n",
      "Starting epoch:  5\n",
      "Iteration: 0 Loss: 0.879083 Accuracy: 0.651700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.624870 Accuracy: 0.677400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 1.020719 Accuracy: 0.675100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.709235 Accuracy: 0.689700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.918384 Accuracy: 0.689900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.867242 Accuracy: 0.675200 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.744365 Accuracy: 0.691900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.919644 Accuracy: 0.684200 Learning rate: 0.005512 Regularization: 0.000617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies mean: 0.679388 Accuracies std: 0.012263 Range: 0.040200\n",
      "Starting epoch:  6\n",
      "Iteration: 0 Loss: 0.999977 Accuracy: 0.691000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.948675 Accuracy: 0.676600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 0.936918 Accuracy: 0.685300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.637824 Accuracy: 0.698900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.625877 Accuracy: 0.700300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.855270 Accuracy: 0.671100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.684099 Accuracy: 0.697400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.628089 Accuracy: 0.710900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.691437 Accuracies std: 0.012350 Range: 0.039800\n",
      "Starting epoch:  7\n",
      "Iteration: 0 Loss: 0.548915 Accuracy: 0.704600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.856083 Accuracy: 0.712000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 0.649481 Accuracy: 0.692500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.739217 Accuracy: 0.705700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.909225 Accuracy: 0.702800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.652784 Accuracy: 0.716500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.497254 Accuracy: 0.710700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.804313 Accuracy: 0.716600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.707675 Accuracies std: 0.007523 Range: 0.024100\n",
      "Starting epoch:  8\n",
      "Iteration: 0 Loss: 0.714818 Accuracy: 0.693100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.745240 Accuracy: 0.709800 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 0.840953 Accuracy: 0.695700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.860115 Accuracy: 0.712700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.518010 Accuracy: 0.727700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.549636 Accuracy: 0.716200 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.561894 Accuracy: 0.696100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.661326 Accuracy: 0.713100 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.708050 Accuracies std: 0.011300 Range: 0.034600\n",
      "Starting epoch:  9\n",
      "Iteration: 0 Loss: 0.593535 Accuracy: 0.723700 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 100 Loss: 0.455754 Accuracy: 0.721300 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 200 Loss: 0.399007 Accuracy: 0.712400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 300 Loss: 0.609297 Accuracy: 0.723900 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 400 Loss: 0.594958 Accuracy: 0.712000 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 500 Loss: 0.491618 Accuracy: 0.707600 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 600 Loss: 0.547875 Accuracy: 0.724400 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Iteration: 700 Loss: 0.627756 Accuracy: 0.718500 Learning rate: 0.005512 Regularization: 0.000617\n",
      "Accuracies mean: 0.717975 Accuracies std: 0.006072 Range: 0.016800\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n",
      "Best accuracy: %f 0.7277\n",
      "Accuracy with LR=0.005512 and Reg=0.000617 ---> 0.735300\n",
      "Best acc after 10 epochs: 0.735300 with lr: 1.138115e-02 and reg: 0.001155\n"
     ]
    }
   ],
   "source": [
    "# From the previous result, we see that the best accuracy is with LR = ~9.66e-03, thus we can look in a finer\n",
    "# interval, e.g. 10**[-2, -1.5]\n",
    "# since Reg = 0.0011, let us look in the interval [-4, -2]\n",
    "# Then in this step, we will look in narrower interval to fine tune the LR and Reg values.\n",
    "\n",
    "# Let us try for 10 combinations of regularization and learning rates\n",
    "total_tests = 5\n",
    "num_epochs = 10\n",
    "accuracies = {}\n",
    "best_acc = 0\n",
    "for test in range(total_tests):\n",
    "    learning_rate = 10**np.random.uniform(-2.5, -1.5)\n",
    "    reg = 10**np.random.uniform(-4, -2)\n",
    "    update_param, acc = train_CNN(\n",
    "                num_filters,\n",
    "                num_epochs=num_epochs,\n",
    "                learning_rate=learning_rate, \n",
    "                reg=reg,\n",
    "                print_every=100,\n",
    "                minibatch_size = 64, \n",
    "                dropout_p=1.0)\n",
    "    accuracies[(learning_rate, reg)] = acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = update_param\n",
    "    print('Accuracy with LR=%f and Reg=%f ---> %f' %(learning_rate, reg, best_acc))\n",
    "\n",
    "accs = sorted([(acc, lr_reg )for lr_reg, acc in accuracies.items()], reverse=1)\n",
    "print('Best acc after %d epochs: %f with lr: %e and reg: %f' \n",
    "      %(num_epochs, accs[0][0], accs[0][1][0], accs[0][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.7353\n",
      "The predicted class is:  Airplane\n",
      "The correct class is:  Airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Firstly, we create the placeholder that will receive the test data\n",
    "x = tf.placeholder(tf.float32, [1, 32, 32, 3])\n",
    "x_acc = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "\n",
    "\n",
    "# Since we used a dictionary instead of a list for storing the parameters, but the training routine returns\n",
    "# a list, we first convert manually the list into a dictionary\n",
    "update_params = {}\n",
    "list_of_keys = ['W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4', 'W5','b5']\n",
    "update_params = {key : best_model[i] for i,key in enumerate(list_of_keys)}\n",
    "\n",
    "\n",
    "# We then, call the fordward function\n",
    "scores = five_layer_CNN(x=x, params=update_params, classes=10 ,training=False)\n",
    "scores_acc = five_layer_CNN(x=x_acc, params=update_params, classes=10 ,training=False)\n",
    "\n",
    "idx = np.random.randint(10000)\n",
    "\n",
    "# Let's now create run the prediction graph\n",
    "with tf.Session() as sess2:\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    scores2 = sess2.run(scores, feed_dict={x:x_test[idx].reshape(1, 32, 32, 3)})\n",
    "    \n",
    "    acc = compute_accuracy(sess2, 64, scores_acc, x_acc)\n",
    "    \n",
    "    print('Accuracy is: ', acc)\n",
    "    \n",
    "    print('The predicted class is: ', classes[np.argmax(scores2)])\n",
    "    print('The correct class is: ', classes[y_test[idx]])\n",
    "    \n",
    "    plt.imshow(x_test[idx].astype(np.int32))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_file\n",
      "The predited class is:  Automobile\n",
      "The correct class is:  Automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess2:\n",
    "    # Load saved Model\n",
    "    saver = tf.train.import_meta_graph('checkpoint_file.meta')\n",
    "    saver.restore(sess2, 'checkpoint_file')\n",
    "    \n",
    "    # Load saved points\n",
    "    # Scores includes the complete model, with final parameters\n",
    "    scores = tf.get_collection('scores')[0]\n",
    "    # Saved placeholders, since we only want to run the inference graph, we only load x\n",
    "    x = tf.get_collection('images')[0]\n",
    "    \n",
    "    # Variables to Test the accuracy is the best model's one and not just the last one\n",
    "    x_acc = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    \n",
    "    # Choose radom point in test data\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.imshow(x_test[idx].astype(np.int32))\n",
    "    \n",
    "    # Calculate the score\n",
    "    scores2 = sess2.run(scores, feed_dict={x:x_test[idx].reshape(1, 32, 32, 3)})\n",
    "    \n",
    "           \n",
    "    print('The predited class is: ', classes[np.argmax(scores2)])\n",
    "    print('The correct class is: ', classes[y_test[idx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
