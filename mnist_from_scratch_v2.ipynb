{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low level Tensorflow model for MNIST/CIFAR10 classification\n",
    "Ok, I understand that there are many really good Tensorflow tutorials out there. I have completed a couple myself. Particularly, I cannot recommend enought those from Stanford CS231n and Andrew Ng's Deep Learning Coursera. However, when I tried to create my first own project from scratch I found myself having to look for help in my previous sample homeworks from CS231n and Coursera. Thus, I decided that to get a real understanding of Tensorflow, I had to complete some projects from zero, without any sort of template.\n",
    "Although this notebook is quite a selfish project to improve my proficiency, I reckon it may be of use to at least one individual out there in a similar situation, so feel free to use this code.\n",
    "For familiriaty, I will be using the ever useful MNIST database of handwritten characters.\n",
    "Please note that this Notebook assumes Deep Learning Understanding at a level of the courses mentioned above, as well as python, and is only a Tensorflow getting started tutorial from scratch.\n",
    "Also, please note that this notebook is the first of a 3-part series, the other two series will use CNNs and CIFAR10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and preprocessing the data\n",
    "As mentioned before, I will be using MNIST and CIFAR10 for this notebook. \n",
    "We can use Tensorflow-Keras with the command 'tf.keras.datasets.mnist.load_data()' and download the database online, or we can download it from:\n",
    "https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    "For more detailed information on the MNIST dataset, please refer to [LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. Also please see http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "In a second experiment, we will use the CIFAR10 dataset, which we will download from Alex Krizhevsky website at University of Toronto at https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "For more details of the CIFAR10, dataset please refer to https://www.cs.toronto.edu/~kriz/cifar.html or \n",
    "Krizhevsky, A., \"LearningMultipleLayersofFeaturesfromTinyImages\", 2009, https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use MNIST\n",
    "#(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Uncomment to use CIFAR10\n",
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "# Define dataset to use\n",
    "if x_test.shape[1] == 28:\n",
    "    dataset = 'MNIST'\n",
    "    PIXELS = 784\n",
    "else:\n",
    "    dataset = 'CIFAR10'\n",
    "    PIXELS = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (50000, 32, 32, 3)\n",
      "Train labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# It is a good idea to visualise the data we just loaded.\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image shape:  (32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdf7849c198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So, as expected we have 60,000 training images and 10,0000 for testing. What is\n",
    "# each image shape? Let's find out\n",
    "print('Train image shape: ', x_train[1].shape)\n",
    "\n",
    "# Knowing it is a matrix shape, we can randomly show any of the numbers\n",
    "rnd_idx = np.random.randint(x_train.shape[0])\n",
    "plt.imshow(x_train[rnd_idx].astype(np.int32)) #Using astype guarantess imshow work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity and to use default TF settings, we cast the data to int32 and float32\n",
    "# Since, the dataset is relatively small, in most cases, this is not a problem\n",
    "y_train = y_train.astype(np.int32).reshape(-1)\n",
    "y_test = y_test.astype(np.int32).reshape(-1)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types, not necessary, perhaps educational\n",
    "type(y_train)\n",
    "isinstance(y_test, np.ndarray) #validate if it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data are numpy arrays\n",
    "assert (isinstance(x_train, np.ndarray) and isinstance(y_train, np.ndarray)), 'No ndarray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we define a function to divide our data in N mini batches, this is an important step, to allow for mini batch \n",
    "# gradient descent\n",
    "\n",
    "def mini_batches(mini_batch_size, data_x, data_y = None):\n",
    "    # First we validate the data is of the expected type, and the number of labels meet the number of training samples\n",
    "    assert data_x.shape[0] == data_y.shape[0], 'X number of samples not equal to Y number of samples'\n",
    "    assert (isinstance(data_x, np.ndarray) and isinstance(data_y, np.ndarray)), 'Data not numpy array'\n",
    "    \n",
    "    N = data_x.shape[0] # Get the number of samples\n",
    "    idxs = np.arange(N) \n",
    "    # Shuffle data, this may not be so critical in this example, but it is important for most applications, to avoid\n",
    "    # strong correlations in mini batches\n",
    "    np.random.shuffle(idxs)\n",
    "    data_x = data_x[idxs] # Shuffle training samples\n",
    "    data_y = data_y[idxs] # Shuffle labels (don't forget)\n",
    "    \n",
    "    # Finally return the data in minibatches of the desired size\n",
    "    # List comprehension is so cool, technically this is returning a generator but the principle is the same\n",
    "    return ((data_x[i:i+mini_batch_size], data_y[i:i+mini_batch_size]) for i in range(0, N, mini_batch_size))\n",
    "\n",
    "type(mini_batches(64, x_test, y_test)) # Check type returned by function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1].shape # In case we need to check the shape of one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if using list comprehension instead of generator\n",
    "# a = mini_batches(500, x_test, y_test)\n",
    "# print((a[5][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n",
      "7 (64, 32, 32, 3) (64,)\n",
      "8 (64, 32, 32, 3) (64,)\n",
      "9 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "# To iterate through the data, we use something like this\n",
    "for t,(x,y) in enumerate(mini_batches(64, x_train, y_train)):\n",
    "    print(t, x.shape, y.shape) # Print the shape for each minibatch\n",
    "    if t > 8:\n",
    "        break # Stop after the first 10 minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with tensorflow training\n",
    "\n",
    "In this notebook I show a very low level implementation, well not really I'm using Tensorflow, but still low level given TF standards. I reckon this is intuitive and shows what is going on, facilitating the transition to higher level TF and Keras in more complex projects.\n",
    "\n",
    "The approach followed in this notebook is to use functions to define the network architecture, and parameter initialization, as shown in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define the architecture of our FC networks.\n",
    "# I will start with a 4-Layer vanilla (tasty) FC NN with ReLu activations, weight decay regularization (L2),\n",
    "# using the number of hidden units given in, well, hidden_units\n",
    "\n",
    "\n",
    "def init_four_layer_FC(PIXELS, hidden_units):\n",
    "    '''\n",
    "    Initialise the parameters\n",
    "\n",
    "    Inputs:\n",
    "    - PIXELS: Scalar with total number of pixels in the image (for MNIST that would be 28x28 = 784)\n",
    "    - hidden_units: List with number of hidden neurons per layer\n",
    "\n",
    "    Outputs:\n",
    "    - Parameters: List with network parameters\n",
    "    '''\n",
    "    # Extract layer sizes\n",
    "    H1 = hidden_units[0]\n",
    "    H2 = hidden_units[1]\n",
    "    H3 = hidden_units[2]\n",
    "    classes = hidden_units[3]\n",
    "\n",
    "    #     Given that we only have 4 layers initializing with small random numbers should be fine, however we could\n",
    "    #     use a more roburs initialization like that in:   \n",
    "    #     He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,\n",
    "    #     ICCV 2015, https://arxiv.org/abs/1502.01852\n",
    "    #     For example:\n",
    "    '''\n",
    "    w1 = tf.Variable(tf.random_normal(\n",
    "                             (PIXELS, hidden_units1), dtype=tf.float32) * np.sqrt(2.0 / PIXELS), \n",
    "                             dtype=tf.float32)\n",
    "    '''\n",
    "    # First, let's define the weights, we use variables because they are maintained in the graph and can be \n",
    "    # mutated through iterations. If we manually declare the learnable weights, tf.Variables are usally the ones\n",
    "    # to use\n",
    "\n",
    "    # Define 1st layer parameters, note that tf.float32 is the default type, however I leave explicit in case\n",
    "    # we wanted to use different type of data for particular purposes\n",
    "\n",
    "    # Weights are left as normal random with std = 0.01 and mean = 0\n",
    "    # Biases are set to zero\n",
    "    # Since they are learnable parameters they are set to zero\n",
    "\n",
    "    w1 = tf.Variable(tf.random_normal((PIXELS, H1), dtype=tf.float32) * 0.01, dtype=tf.float32, name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(H1, dtype=tf.float32), dtype=tf.float32, name='b1')\n",
    "\n",
    "    w2 = tf.Variable(tf.random_normal((H1, H2), dtype=tf.float32) * 0.01, dtype=tf.float32, name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(H2, dtype=tf.float32), dtype=tf.float32, name='b2')\n",
    "\n",
    "    w3 = tf.Variable(tf.random_normal((H2, H3), dtype=tf.float32) * 0.01, dtype=tf.float32, name='w3')\n",
    "    b3 = tf.Variable(tf.zeros(H3, dtype=tf.float32), dtype=tf.float32, name='b3')\n",
    "\n",
    "    w4 = tf.Variable(tf.random_normal((H3, classes), dtype=tf.float32) * 0.01, dtype=tf.float32, name='w4')\n",
    "    b4 = tf.Variable(tf.zeros(classes, dtype=tf.float32), dtype=tf.float32, name='b4')\n",
    "\n",
    "    # Return parameters\n",
    "    parameters = [w1, b1, w2, b2, w3, b3, w4, b4]\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def four_layer_FC(PIXELS,x, parameters,dataset):\n",
    "    '''\n",
    "    Create the inference graph, define the network architecture\n",
    "    \n",
    "    Inputs:\n",
    "    - PIXELS: Scalar with total number of pixels in the image (for MNIST that would be 28x28 = 784)\n",
    "    - x: Tensor with training or test images of shape (N, 28, 28) for MNIST\n",
    "    - parameters: Tuple with all the learnable weights and biases\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Verify that x Dimensions match \n",
    "    if dataset == 'MNIST':\n",
    "        assert x.shape[1] * x.shape[2] == PIXELS, 'Image dimensions not as expected'\n",
    "    else:\n",
    "        assert x.shape[1] * x.shape[2] * x.shape[3] == PIXELS, 'Image dimensions not as expected'\n",
    "    # Extract learning parameters\n",
    "    w1, b1, w2, b2, w3, b3, w4, b4 = parameters\n",
    "    # Implement architecture\n",
    "    x = tf.reshape(x,(-1, PIXELS))\n",
    "    \n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "    a1 = tf.nn.relu(h1)\n",
    "    \n",
    "    h2 = tf.matmul(a1, w2) + b2\n",
    "    a2 = tf.nn.relu(h2)\n",
    "    \n",
    "    h3 = tf.matmul(a2, w3) + b3\n",
    "    a3 = tf.nn.relu(h3)\n",
    "    \n",
    "    scores = tf.matmul(a3, w4) + b4\n",
    "\n",
    "    return scores\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to be sure that the model produces an expected output for a given input. Thus, the following step just veryfies that running data through produces a tensor of the expected shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josh/anaconda3/envs/cs231n/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# Help function to test if the inference graph produces the expected output dimensions given an input\n",
    "# in this case the output should be of shape (N, 10)\n",
    "\n",
    "def test_FC(num_samples, dataset):\n",
    "    # Let us declare some useful constants\n",
    "    if dataset == 'MNIST':\n",
    "        PIXELS = x_test.shape[1] * x_test.shape[2]\n",
    "    elif dataset == 'CIFAR10':\n",
    "        PIXELS = x_test.shape[1] * x_test.shape[2] * x_test.shape[3]\n",
    "    hidden_units = [100, 100, 100, 10]\n",
    "    \n",
    "    # Reset the default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Define placeholder\n",
    "    if dataset == 'MNIST':\n",
    "        x = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "    else:\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    \n",
    "    # Obtain parameters\n",
    "    parameters = init_four_layer_FC(PIXELS, hidden_units)\n",
    "    \n",
    "    # Add scores to the graph\n",
    "    scores = four_layer_FC(PIXELS, x, parameters, dataset)\n",
    "    \n",
    "    # Create session and run it\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        test = sess.run(scores, feed_dict={x:x_train[:num_samples]})\n",
    "        print(test.shape)\n",
    "\n",
    "# Test our model output size\n",
    "test_FC(10, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the training model\n",
    "In this point we will start training our graph. For this we will use a Tensorflow session to run the inference graph and the training operations. This will look similiar to test_FC(), plus the required components to define a loss function and carry out learning step operations. For simplicity let us use vanilla Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines the complete training graph\n",
    "\n",
    "def train_FC_model(hidden_units, \n",
    "                   num_epochs=10,\n",
    "                   PIXELS=784,\n",
    "                   learning_rate=0.05,\n",
    "                   reg=0,\n",
    "                   print_every=100,\n",
    "                   minibatch_size = 64):\n",
    "    '''\n",
    "    Train Tensorflow model\n",
    "    \n",
    "    Inputs:\n",
    "    - hidden_units: List with number of hidden neurons per layer\n",
    "    - num_epochs: Integer with the number of epochs to run, an epoch is a complete pass in the whole training set\n",
    "    - PIXELS: Scalar with total number of pixels\n",
    "    - learning_rate: Float with the learning rate to use for updates, i.e. the step size towards the minimum\n",
    "    - reg: L2 regularization strength, default is set to 0 for no regularization\n",
    "    - print_every: This is a helping variable to stop during training and evaluate loss functions and accuracy\n",
    "    - minibatch_size: Integer with the number of elements in minibatch\n",
    "    \n",
    "    Outputs:\n",
    "    - updated_parameters: List with update parameters\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Reset default graph.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Define training data placeholders using expected MNIST data dimensions\n",
    "    if dataset == 'MNIST':\n",
    "        x = tf.placeholder(tf.float32, [None, 28, 28], name = 'x_train') # Training data\n",
    "        y = tf.placeholder(tf.int32,[None, ], name='y_train') # Labels\n",
    "    elif dataset == 'CIFAR10':\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32, 3], name = 'x_train') # Training data\n",
    "        y = tf.placeholder(tf.int32, [None, ], name = 'y_train') # Training data\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add these placeholders to graph in saver, this will allow for easy model restore\n",
    "    tf.add_to_collection('images', x)\n",
    "    tf.add_to_collection('labels', y)\n",
    "\n",
    "    # Load parameters by running the previously defined function\n",
    "    parameters = init_four_layer_FC(PIXELS, hidden_units)\n",
    "    \n",
    "    # Add scores to graph using the function we coded, and the parameters\n",
    "    scores = four_layer_FC(PIXELS, x, parameters, dataset)\n",
    "    \n",
    "    # Save scores to model, this is key since it will allow using it for inference after restore\n",
    "    tf.add_to_collection('scores', scores)\n",
    "    \n",
    "    # Once the scores are computed, we need to obtain our Loss. Given the data, we will use Cross entropy \n",
    "    # Using Tensorflow implementation of Cross entropy\n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=scores, labels=y) # Each sample loss\n",
    "    data_loss = tf.reduce_mean(losses, name='loss') # take minibatch average\n",
    "    \n",
    "    # Should we want to use l2 regularization, default is zero, i.e., no regularization\n",
    "    reg_loss = tf.reduce_mean(reg * (tf.nn.l2_loss(parameters[0])\n",
    "                                     + tf.nn.l2_loss(parameters[2])\n",
    "                                     + tf.nn.l2_loss(parameters[4])\n",
    "                                     + tf.nn.l2_loss(parameters[0])))\n",
    "    \n",
    "    loss = data_loss + reg_loss # Compute total loss\n",
    "    \n",
    "    # Up to this point we have computed the complete forward pass of the data. \n",
    "    # Since, this is 'low level' Tensorflow we need to compute the gradients for the loss \n",
    "    # w.r.t. all the learnable parameters. As I said, low level but still Tensorflow. So let's use tf.gradients!\n",
    "    grad_parameters = tf.gradients(loss, parameters) # Loss gradient w.r.t. parameters\n",
    "\n",
    "    # We need to update the weights manually, for this we can use tf.assign, or tf.assing_sub\n",
    "    # Using SGD, we need to update each parameter independently, so list comprehension works well\n",
    "    updated_parameters = [tf.assign_sub(w, learning_rate * grad)\n",
    "                          for w, grad in zip(parameters, grad_parameters)]\n",
    "    \n",
    "    tf.add_to_collection('weights', updated_parameters)\n",
    "    \n",
    "    accuracies = np.zeros(10) # Helping variable to store accuracies\n",
    "    losses = np.zeros(10) # Helping variable to store accuracies\n",
    "    \n",
    "    # Create saver to save the model\n",
    "    saver = tf.train.Saver()\n",
    "    # Now, recall we have only created the graph, in order to run it and train, we need a Session\n",
    "    with tf.Session() as sess:\n",
    "        # Initialise variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Train the model for num_epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            print('Epoch number: ', epoch) # Allow us to see what epoch we are running\n",
    "            \n",
    "            # Run the necessary iterations given the number of minibatches, this follows the function defined\n",
    "            # at the beginning of the notebook\n",
    "            for iteration,(x_mb, y_mb) in enumerate(mini_batches(minibatch_size, x_train, y_train)):\n",
    "                # The following line calculates the loss for the minibatch.\n",
    "                # Recall TF knows what is needed to run a function and will run accordinly, e.g. scores before the\n",
    "                # loss. Also note that we only need to feed the data needed into a placeholder. In this case, we \n",
    "                # feed the minibatch training samples and labels\n",
    "                loss_mb, update_param = sess.run([loss, updated_parameters], feed_dict={x:x_mb, y:y_mb})\n",
    "                \n",
    "                # The following condition allows a sanity check by printing accuracies and loss\n",
    "                if iteration % print_every == 0:\n",
    "                    # We define this function in the next cell\n",
    "                    accuracy = compute_accuracy(sess, minibatch_size, scores, x)\n",
    "                    accuracies[int(iteration/100)]=accuracy # save current accuracy\n",
    "                    losses[int(iteration/print_every)] = loss_mb\n",
    "                    print('Iteration: %d Loss: %f Accuracy: %f Learning rate: %f'\n",
    "                          %(iteration, loss_mb, accuracy, learning_rate))\n",
    "        \n",
    "        # We could use learning rate decay. There are several conditions we could test to define when to decay.\n",
    "        # E.g. we could use it when accuracy is over e.g. 90%, or the loss stays relatively flat\n",
    "            print('Last losses std: ', np.std(losses))\n",
    "            if np.std(losses) < 0.80:\n",
    "                learning_rate = 0.95 * learning_rate\n",
    "        # Save the \n",
    "        saver.save(sess, 'checkpoint_file')\n",
    "        \n",
    "    return update_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(sess, minibatch_size, scores, x):\n",
    "    '''\n",
    "    This function computes the accuracy of the current model\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: it needs a current tf.Session to run the scores\n",
    "    - minibatch_size: The size of the mini batch to run the scores\n",
    "    - scores: TF operation to run\n",
    "    - x: test data\n",
    "    \n",
    "    Outputs:\n",
    "    - acc: Accuracy\n",
    "    \n",
    "    '''\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    for it, (xtest_mb, ytest_mb) in enumerate(mini_batches(minibatch_size, x_test, y_test)):\n",
    "        scores_test = sess.run(scores, feed_dict={x:xtest_mb})\n",
    "        y_pred = np.argmax(scores_test, axis=1)\n",
    "\n",
    "#         In case we would like to compare some elements of the predicted and ground truth arrays\n",
    "#         if it % 200 == 0:\n",
    "#             print('y_pred: ', y_pred[:10])\n",
    "#             print('y_test: ', ytest_mb[:10])\n",
    "\n",
    "        num_samples += xtest_mb.shape[0]\n",
    "        num_correct += np.sum(np.equal(y_pred, ytest_mb))\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:  0\n",
      "Iteration: 0 Loss: 2.304721 Accuracy: 0.103000 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 2.224907 Accuracy: 0.137600 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 2.057334 Accuracy: 0.225600 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 2.018455 Accuracy: 0.261000 Learning rate: 0.005000\n",
      "Last losses std:  1.056570604110854\n",
      "Epoch number:  1\n",
      "Iteration: 0 Loss: 1.878428 Accuracy: 0.289400 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 1.982928 Accuracy: 0.268200 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 1.862534 Accuracy: 0.318100 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 1.799237 Accuracy: 0.323600 Learning rate: 0.005000\n",
      "Last losses std:  0.9223359600883845\n",
      "Epoch number:  2\n",
      "Iteration: 0 Loss: 1.802752 Accuracy: 0.341600 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 1.910864 Accuracy: 0.326000 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 1.893183 Accuracy: 0.334600 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 1.786185 Accuracy: 0.353200 Learning rate: 0.005000\n",
      "Last losses std:  0.9061067465689635\n",
      "Epoch number:  3\n",
      "Iteration: 0 Loss: 1.632721 Accuracy: 0.395000 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 1.632538 Accuracy: 0.374500 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 1.625954 Accuracy: 0.403500 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 1.649912 Accuracy: 0.377400 Learning rate: 0.005000\n",
      "Last losses std:  0.8011405464153695\n",
      "Epoch number:  4\n",
      "Iteration: 0 Loss: 1.712760 Accuracy: 0.387500 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 1.734252 Accuracy: 0.415300 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 1.849372 Accuracy: 0.403700 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 1.741615 Accuracy: 0.426000 Learning rate: 0.005000\n",
      "Last losses std:  0.8626258656450114\n",
      "Epoch number:  5\n",
      "Iteration: 0 Loss: 1.616988 Accuracy: 0.402700 Learning rate: 0.005000\n",
      "Iteration: 100 Loss: 1.570655 Accuracy: 0.393200 Learning rate: 0.005000\n",
      "Iteration: 200 Loss: 1.484597 Accuracy: 0.421300 Learning rate: 0.005000\n",
      "Iteration: 300 Loss: 1.546255 Accuracy: 0.412000 Learning rate: 0.005000\n",
      "Last losses std:  0.7622054996483251\n",
      "Epoch number:  6\n",
      "Iteration: 0 Loss: 1.873564 Accuracy: 0.372500 Learning rate: 0.004750\n",
      "Iteration: 100 Loss: 1.659047 Accuracy: 0.435100 Learning rate: 0.004750\n",
      "Iteration: 200 Loss: 1.708545 Accuracy: 0.441300 Learning rate: 0.004750\n",
      "Iteration: 300 Loss: 1.816758 Accuracy: 0.382700 Learning rate: 0.004750\n",
      "Last losses std:  0.8660831514653666\n",
      "Epoch number:  7\n",
      "Iteration: 0 Loss: 1.685526 Accuracy: 0.389200 Learning rate: 0.004750\n",
      "Iteration: 100 Loss: 1.684980 Accuracy: 0.440900 Learning rate: 0.004750\n",
      "Iteration: 200 Loss: 1.628330 Accuracy: 0.435100 Learning rate: 0.004750\n",
      "Iteration: 300 Loss: 1.492000 Accuracy: 0.457100 Learning rate: 0.004750\n",
      "Last losses std:  0.796528895625251\n",
      "Epoch number:  8\n",
      "Iteration: 0 Loss: 1.573028 Accuracy: 0.440000 Learning rate: 0.004513\n",
      "Iteration: 100 Loss: 1.490687 Accuracy: 0.452000 Learning rate: 0.004513\n",
      "Iteration: 200 Loss: 1.587635 Accuracy: 0.436200 Learning rate: 0.004513\n",
      "Iteration: 300 Loss: 1.559031 Accuracy: 0.456400 Learning rate: 0.004513\n",
      "Last losses std:  0.7609759400014732\n",
      "Epoch number:  9\n",
      "Iteration: 0 Loss: 1.494422 Accuracy: 0.440900 Learning rate: 0.004287\n",
      "Iteration: 100 Loss: 1.503108 Accuracy: 0.461400 Learning rate: 0.004287\n",
      "Iteration: 200 Loss: 1.530545 Accuracy: 0.450900 Learning rate: 0.004287\n",
      "Iteration: 300 Loss: 1.619751 Accuracy: 0.463200 Learning rate: 0.004287\n",
      "Last losses std:  0.7536056492388393\n",
      "Epoch number:  10\n",
      "Iteration: 0 Loss: 1.634795 Accuracy: 0.436600 Learning rate: 0.004073\n",
      "Iteration: 100 Loss: 1.461159 Accuracy: 0.429700 Learning rate: 0.004073\n",
      "Iteration: 200 Loss: 1.412190 Accuracy: 0.456200 Learning rate: 0.004073\n",
      "Iteration: 300 Loss: 1.451097 Accuracy: 0.466400 Learning rate: 0.004073\n",
      "Last losses std:  0.7318639878400003\n",
      "Epoch number:  11\n",
      "Iteration: 0 Loss: 1.678644 Accuracy: 0.477800 Learning rate: 0.003869\n",
      "Iteration: 100 Loss: 1.409473 Accuracy: 0.476900 Learning rate: 0.003869\n",
      "Iteration: 200 Loss: 1.376909 Accuracy: 0.467400 Learning rate: 0.003869\n",
      "Iteration: 300 Loss: 1.440728 Accuracy: 0.468000 Learning rate: 0.003869\n",
      "Last losses std:  0.7272030462326671\n",
      "Epoch number:  12\n",
      "Iteration: 0 Loss: 1.483394 Accuracy: 0.484700 Learning rate: 0.003675\n",
      "Iteration: 100 Loss: 1.439341 Accuracy: 0.477500 Learning rate: 0.003675\n",
      "Iteration: 200 Loss: 1.406336 Accuracy: 0.474000 Learning rate: 0.003675\n",
      "Iteration: 300 Loss: 1.484543 Accuracy: 0.461600 Learning rate: 0.003675\n",
      "Last losses std:  0.7123200712183607\n",
      "Epoch number:  13\n",
      "Iteration: 0 Loss: 1.404778 Accuracy: 0.471500 Learning rate: 0.003492\n",
      "Iteration: 100 Loss: 1.680588 Accuracy: 0.476700 Learning rate: 0.003492\n",
      "Iteration: 200 Loss: 1.477091 Accuracy: 0.488600 Learning rate: 0.003492\n",
      "Iteration: 300 Loss: 1.660334 Accuracy: 0.435900 Learning rate: 0.003492\n",
      "Last losses std:  0.7657657354866918\n",
      "Epoch number:  14\n",
      "Iteration: 0 Loss: 1.386606 Accuracy: 0.477900 Learning rate: 0.003317\n",
      "Iteration: 100 Loss: 1.353342 Accuracy: 0.485700 Learning rate: 0.003317\n",
      "Iteration: 200 Loss: 1.406316 Accuracy: 0.489700 Learning rate: 0.003317\n",
      "Iteration: 300 Loss: 1.450604 Accuracy: 0.475900 Learning rate: 0.003317\n",
      "Last losses std:  0.6858348873987088\n",
      "Epoch number:  15\n",
      "Iteration: 0 Loss: 1.491975 Accuracy: 0.439600 Learning rate: 0.003151\n",
      "Iteration: 100 Loss: 1.507119 Accuracy: 0.473600 Learning rate: 0.003151\n",
      "Iteration: 200 Loss: 1.361850 Accuracy: 0.489800 Learning rate: 0.003151\n",
      "Iteration: 300 Loss: 1.546599 Accuracy: 0.486300 Learning rate: 0.003151\n",
      "Last losses std:  0.7248512721675765\n",
      "Epoch number:  16\n",
      "Iteration: 0 Loss: 1.544622 Accuracy: 0.458100 Learning rate: 0.002994\n",
      "Iteration: 100 Loss: 1.364993 Accuracy: 0.479900 Learning rate: 0.002994\n",
      "Iteration: 200 Loss: 1.361426 Accuracy: 0.496100 Learning rate: 0.002994\n",
      "Iteration: 300 Loss: 1.405944 Accuracy: 0.487400 Learning rate: 0.002994\n",
      "Last losses std:  0.6968792454033182\n",
      "Epoch number:  17\n",
      "Iteration: 0 Loss: 1.304432 Accuracy: 0.483000 Learning rate: 0.002844\n",
      "Iteration: 100 Loss: 1.214250 Accuracy: 0.483000 Learning rate: 0.002844\n",
      "Iteration: 200 Loss: 1.504096 Accuracy: 0.467300 Learning rate: 0.002844\n",
      "Iteration: 300 Loss: 1.297855 Accuracy: 0.488900 Learning rate: 0.002844\n",
      "Last losses std:  0.6551157211749499\n",
      "Epoch number:  18\n",
      "Iteration: 0 Loss: 1.240255 Accuracy: 0.466500 Learning rate: 0.002702\n",
      "Iteration: 100 Loss: 1.466082 Accuracy: 0.466400 Learning rate: 0.002702\n",
      "Iteration: 200 Loss: 1.243340 Accuracy: 0.506700 Learning rate: 0.002702\n",
      "Iteration: 300 Loss: 1.312208 Accuracy: 0.492000 Learning rate: 0.002702\n",
      "Last losses std:  0.647044719899146\n",
      "Epoch number:  19\n",
      "Iteration: 0 Loss: 1.247725 Accuracy: 0.507200 Learning rate: 0.002567\n",
      "Iteration: 100 Loss: 1.320489 Accuracy: 0.489100 Learning rate: 0.002567\n",
      "Iteration: 200 Loss: 1.449851 Accuracy: 0.490500 Learning rate: 0.002567\n",
      "Iteration: 300 Loss: 1.144763 Accuracy: 0.486100 Learning rate: 0.002567\n",
      "Last losses std:  0.6362058607971172\n",
      "WARNING:tensorflow:Issue encountered when serializing weights.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "# Define number of neurons (units) in each hidden layer\n",
    "hidden_units = [100, 100, 100, 10]\n",
    "\n",
    "# Train the model and save weights\n",
    "updated_parameters =  train_FC_model(hidden_units=hidden_units, \n",
    "                                     num_epochs=20,\n",
    "                                     PIXELS=PIXELS, \n",
    "                                     learning_rate=0.005,\n",
    "                                     minibatch_size=128,\n",
    "                                     reg= 0.0, \n",
    "                                     print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w1', 'b1', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4']\n"
     ]
    }
   ],
   "source": [
    "# This instruction is not needed for the tutorial but it is useful to know the variablse in the graph\n",
    "auxL = [op.name for op in tf.get_default_graph().get_operations() if op.op_def and op.op_def.name=='VariableV2']\n",
    "print(auxL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is:  Automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_units = [100, 100, 100, 10]\n",
    "if dataset == 'MNIST':\n",
    "    x = tf.placeholder(tf.float32, [1, 28, 28])\n",
    "    classes = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five',\n",
    "              'Six', 'Seven', 'Eight', 'Nine']\n",
    "elif dataset == 'CIFAR10':\n",
    "    x = tf.placeholder(tf.float32, [1, 32, 32, 3])\n",
    "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
    "              'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "#parameters = init_four_layer_FC(784, hidden_units)\n",
    "# Add scores\n",
    "scores = four_layer_FC(PIXELS, x, updated_parameters,dataset)    \n",
    "#eval_op = tf.nn.top_k(scores)\n",
    "\n",
    "idx = np.random.randint(10000)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if dataset=='MNIST':\n",
    "        scores2 = sess.run(scores, feed_dict={x:x_test[idx].reshape(1, 28, 28)})\n",
    "    else:\n",
    "        scores2 = sess.run(scores, feed_dict={x:x_test[idx].reshape(1, 32, 32, 3)})\n",
    "        \n",
    "    print('The predicted class is: ', classes[np.argmax(scores2)])\n",
    "    plt.imshow(x_test[idx].astype(np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the previously trained model\n",
    "\n",
    "So far we have trained the complete model, computed its accuracy, and validated it with random samples. However, we did the whole process in one go. Since the dataset is relatively simple this is not an issue, nonetheless this would be prohibiting for more complex and larger datasets. Since we saved our trained model, we can just load it and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint_file\n",
      "The predited number is:  Horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset == 'MNIST':\n",
    "    x = tf.placeholder(tf.float32, [1, 28, 28])\n",
    "    classes = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five',\n",
    "              'Six', 'Seven', 'Eight', 'Nine']\n",
    "elif dataset == 'CIFAR10':\n",
    "    x = tf.placeholder(tf.float32, [1, 32, 32, 3])\n",
    "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
    "              'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "with tf.Session() as sess2:\n",
    "    # Load saved Model\n",
    "    saver = tf.train.import_meta_graph('checkpoint_file.meta')\n",
    "    saver.restore(sess2, 'checkpoint_file')\n",
    "    \n",
    "    # Load saved points\n",
    "    # Scores includes the complete model, with final parameters\n",
    "    scores = tf.get_collection('scores')[0]\n",
    "    # Saved placeholders, since we only want to run the inference graph, we only load x\n",
    "    x = tf.get_collection('images')[0]\n",
    "    \n",
    "    # Choose radom point in test data\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.imshow(x_test[idx].astype(np.int32))\n",
    "    \n",
    "    # Calculate the score\n",
    "    if dataset=='MNIST':\n",
    "        scores2 = sess2.run(scores, feed_dict={x:x_test[idx].reshape(1, 28, 28)})\n",
    "    else:\n",
    "        scores2 = sess2.run(scores, feed_dict={x:x_test[idx].reshape(1, 32, 32, 3)})\n",
    "        \n",
    "    print('The predited number is: ', classes[np.argmax(scores2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
